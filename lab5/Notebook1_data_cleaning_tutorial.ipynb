{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK_XNOusKgSV"
   },
   "source": [
    "# Data Cleaning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZK564joKxVW"
   },
   "source": [
    "## Introduction\n",
    "In this notebook, we will share a few common tasks you will perform in data cleaning, using the **[New York City Airbnb](https://github.com/ManarOmar/New-York-Airbnb-2019)** Open Data from Kaggle as an example. \n",
    "\n",
    "In particular, it will be centered around these 3 topics below:\n",
    "\n",
    "* Missing data\n",
    "* Inconsistent data/Irrelevant features\n",
    "* Outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB0Bq0ByMG4V"
   },
   "source": [
    "## 1. Overview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__GCTPyuMOsv"
   },
   "source": [
    "### Importing Libraries\n",
    "\n",
    "First we start by importing the necessary libraries for data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1648905360345,
     "user": {
      "displayName": "Ziqiao Ao",
      "userId": "12315067596244745838"
     },
     "user_tz": -480
    },
    "id": "q6pBkqcoKhKW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut9H5XBoMUXH"
   },
   "source": [
    "### Load the data\n",
    "\n",
    "Then we load the data. In this case, we loaded it from a csv file hosted on Github, but you can upload the csv file and import that data using pd.read_csv()\n",
    "Notice that we copy the original dataset using .copy(). This is for a data cleaning example later on in the article. It’s also good practice to copy the data set when you want to test something out so you won’t have to re-run the entire notebook if you make a mistake somewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1648905361466,
     "user": {
      "displayName": "Ziqiao Ao",
      "userId": "12315067596244745838"
     },
     "user_tz": -480
    },
    "id": "1GU0XCoSMTJ6",
    "outputId": "fb0610d7-3c08-492f-c6d7-5abf13b78537"
   },
   "outputs": [],
   "source": [
    "airbnb_url = 'https://raw.githubusercontent.com/ManarOmar/New-York-Airbnb-2019/master/AB_NYC_2019.csv'\n",
    "\n",
    "airbnb_ori = pd.read_csv(airbnb_url)\n",
    "airbnb = airbnb_ori.copy()\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVe7quNpKIUn"
   },
   "source": [
    "### Data info\n",
    "Calling info() on our dataset tells us tons of information about our data frame like the shape (rows, columns), the data type of our features, and the memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648905361466,
     "user": {
      "displayName": "Ziqiao Ao",
      "userId": "12315067596244745838"
     },
     "user_tz": -480
    },
    "id": "7nGnuk1LKQts",
    "outputId": "81f6f033-a158-463e-caf6-4c696405fb47"
   },
   "outputs": [],
   "source": [
    "airbnb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LoyNnwhKXIU"
   },
   "source": [
    "### Data Type\n",
    "Separating our features into numerical and categorical early on is useful and here is a helper function that does that. This is accomplished by using the select_dtypes() function that columns with the ‘object’ data type as categorical and the rest as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648905361467,
     "user": {
      "displayName": "Ziqiao Ao",
      "userId": "12315067596244745838"
     },
     "user_tz": -480
    },
    "id": "Pd77w0NkKVFz",
    "outputId": "8ad475cf-87a2-43dd-ba58-20a00a47cc41"
   },
   "outputs": [],
   "source": [
    "cat_df = airbnb.select_dtypes(include=['object'])\n",
    "num_df = airbnb.select_dtypes(exclude=['object'])\n",
    "\n",
    "def printColumnTypes(non_numeric_df, numeric_df):\n",
    "    '''separates non-numeric and numeric columns'''\n",
    "    print(\"Non-Numeric columns:\")\n",
    "    for col in non_numeric_df:\n",
    "        print(f\"{col}\")\n",
    "    print(\"\")\n",
    "    print(\"Numeric columns:\")\n",
    "    for col in numeric_df:\n",
    "        print(f\"{col}\")\n",
    "        \n",
    "printColumnTypes(cat_df, num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuL7PB4NKhyU"
   },
   "source": [
    "Now we have some idea of our data, we can move on to cleaning it by first checking for missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cslr3jRhKjM0"
   },
   "source": [
    "## 2. Visualize Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWETzJogKnCw"
   },
   "source": [
    "Missing data is common in all kinds of data and is tricky to deal with. Most machine learning techniques do not work with missing values and it has to be addressed early on.\n",
    "\n",
    "The two common methods to deal with missing values are\n",
    "\n",
    "* dropping the rows / columns\n",
    "* imputing them based on other observations i.e. the mean or median\n",
    "\n",
    "There are a few problems to these approaches.\n",
    "\n",
    "For example, by dropping rows/columns, you’re essentially losing information that might be useful for prediction\n",
    "On the other hand, imputing values will introduce bias to your data but it still might better than removing your features.\n",
    "\n",
    "Here are a couple useful helper functions you can use to visualize missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uO-ztDR1K3vj"
   },
   "source": [
    "### Columns with missing data\n",
    "\n",
    "This function only prints out columns with missing values, and shows its amount\n",
    "\n",
    "If you want to see missing values for all columns, use this command:\n",
    "\n",
    "*df.isnull().sum()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRx9e-P3K1NZ"
   },
   "outputs": [],
   "source": [
    "def missing_cols(df):\n",
    "    '''prints out columns with its amount of missing values'''\n",
    "    total = 0\n",
    "    for col in df.columns:\n",
    "        missing_vals = df[col].isnull().sum()\n",
    "        total += missing_vals\n",
    "        if missing_vals != 0:\n",
    "            print(f\"{col} => {df[col].isnull().sum()}\")\n",
    "    \n",
    "    if total == 0:\n",
    "        print(\"no missing values left\")\n",
    "            \n",
    "missing_cols(airbnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-fqvH9vLHen"
   },
   "source": [
    "### Percentage missing\n",
    "\n",
    "This gives you the percentage of missing values in each of the columns. Knowing the percentage can be useful in determining whether you should drop the column.\n",
    "\n",
    "The percentage is calculated using the **mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0RN6KDQLD2A"
   },
   "outputs": [],
   "source": [
    "def perc_missing(df):\n",
    "    '''prints out columns with missing values with its %'''\n",
    "    for col in df.columns:\n",
    "        pct = df[col].isna().mean() * 100\n",
    "        if (pct != 0):\n",
    "            print('{} => {}%'.format(col, round(pct, 2)))\n",
    "    \n",
    "perc_missing(airbnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDjlyLVELQXB"
   },
   "source": [
    "### Heatmap of missing values\n",
    "Heatmaps are also useful to visualize your missing values, in particular at which point of the data do missing values exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GewWe60gLTcX"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(airbnb.isnull(), yticklabels=False, cmap='viridis', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn0bOceDLYgC"
   },
   "source": [
    "Now that you know which columns have missing values, it’s time to deal with them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfSy9GN8LedW"
   },
   "source": [
    "## 3. Dealing with Missing Data\n",
    "\n",
    "Some common techniques shared in this lab are:\n",
    "1. Drop the feature\n",
    "2. Drop the row\n",
    "3. Impute the missing value\n",
    "4. Replace it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BA7fpr7Lq_O"
   },
   "source": [
    "### Dropping feature\n",
    "Dropping feature usually isn’t recommended because you’re losing information. But if you’re sure that the column isn’t important, or simply has too many missing values, you can choose to drop them. For example, for this dataset, the host_name column was removed for ethical reasons, and id was removed because it was was unnecessary.\n",
    "\n",
    "To drop features, use drop and set axis to 1 and inplace to true. Axis is 1 because we want to drop columns (0 means row), and inplace is True because you're transforming it directly on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L20Apw24LyyC"
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns that are not important\n",
    "colsToDrop = ['id','host_name','last_review']\n",
    "\n",
    "airbnb.drop(colsToDrop, axis=1, inplace=True)\n",
    "\n",
    "missing_cols(airbnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlJKSniIMCox"
   },
   "source": [
    "### Dropping the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9V058TALw5F"
   },
   "outputs": [],
   "source": [
    "# remove rows with missing values in price\n",
    "airbnb['price'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsCmNmQ6MJ7i"
   },
   "source": [
    "### Imputing\n",
    "\n",
    "For imputing, there are 3 main techniques shown below.\n",
    "1. **fillna** — filling in null values based on given value (mean, median, mode, or specified value)\n",
    "2. **bfill** / ffill — stands for backward fill and forward fill (filling in missing values based on the value after or before the column.)\n",
    "3. Simple Imputer — Sk-learn’s built-in function that imputes missing values (commonly used alongside a pipeline when building ML models)\n",
    "\n",
    "Below you can find examples of applying these methods to the price column if it had missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-koLm0lMS3H"
   },
   "outputs": [],
   "source": [
    "# imputing price with mean\n",
    "price_mean_value = round(airbnb['price'].mean(), 2)\n",
    "airbnb['price'].fillna(price_mean_value, inplace=True)\n",
    "\n",
    "# imputing price with median\n",
    "price_median_value = round(airbnb['price'].median(), 2)\n",
    "airbnb['price'].fillna(price_median_value, inplace=True)\n",
    "\n",
    "# imputing with bfill or ffill\n",
    "airbnb['price'].bfill(inplace=True)\n",
    "airbnb['price'].ffill(inplace=True)\n",
    "\n",
    "# imputing with SimpleImputor from the sklearn library\n",
    "from sklearn.impute import SimpleImputer\n",
    "# define the imputer\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='mean') # or median\n",
    "\n",
    "airbnb[['price']] = imr.fit_transform(airbnb[['price']])\n",
    "\n",
    "# use strategy = 'most_frequent' for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD927jwLMWuA"
   },
   "source": [
    "### Replace\n",
    "\n",
    "To replace values, the ***fillna*** function is also used.\n",
    "\n",
    "You define the value you want to replace in the key, and the substitute in the value — {column_name: replacement_for_NA}\n",
    "\n",
    "Here are examples for replacing values in the columns reviews_per_month and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOrjRFBJMVlL"
   },
   "outputs": [],
   "source": [
    "# replace null values in reviews_per_month with 0 \n",
    "airbnb.fillna({'reviews_per_month':0}, inplace=True)\n",
    "\n",
    "missing_cols(airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfQg_OeRMfeI"
   },
   "outputs": [],
   "source": [
    "# replace null values in name with 'None'\n",
    "airbnb.fillna({'name':'None'}, inplace=True)\n",
    "\n",
    "missing_cols(airbnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4GxPnzFMqCL"
   },
   "source": [
    "Now we have no missing values left!\n",
    "\n",
    "Let’s move on to dealing with inconsistent or irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_X6ogvVMvel"
   },
   "source": [
    "## 4. Inconsistent data/Irrelevant features\n",
    "\n",
    "Inconsistent data refers to things like spelling errors in your data, column names that are not relevant to the data, the wrong data type, etc.\n",
    "\n",
    "Here are a couple examples for dealing with these issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HePYOtFaM3V-"
   },
   "source": [
    "### Remove rows based on regex\n",
    "\n",
    "Let’s say you want to remove rows that contain a certain word. \n",
    "\n",
    "Take the word noisy/Noisy as an example, and the function str.contains() is used to find the indexes that contain those rows.\n",
    "\n",
    "Then, using the drop function and setting axis to index to drop those rows.\n",
    "\n",
    "Printing out the number of rows, you can see it reduced by three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFcTc11fMpgT"
   },
   "outputs": [],
   "source": [
    "# example: remove rows that contain the target word\n",
    "target = '[Nn]oisy'\n",
    "\n",
    "noisy_airbnb = airbnb[airbnb['name'].str.contains(target, regex=True)]\n",
    "\n",
    "# show rows that contains the word noisy\n",
    "print(noisy_airbnb['name'])\n",
    "\n",
    "# get the index that contains the word noisy\n",
    "index_to_drop = noisy_airbnb['name'].index\n",
    "\n",
    "# print(index_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PR0zpBJNPjb"
   },
   "outputs": [],
   "source": [
    "# drop rows based on index\n",
    "airbnb.drop(index_to_drop, axis='index', inplace=True)\n",
    "\n",
    "print(len(airbnb_ori))\n",
    "print(len(airbnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49Y4y-1sOC23"
   },
   "source": [
    "### Spelling errors in categorical data\n",
    "Sometimes your categorical data might have spelling errors or different capitalization that can mess up your categorization.\n",
    "\n",
    "I will be using the *neighbourhood_group* column as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMqTXP6fOIRI"
   },
   "outputs": [],
   "source": [
    "airbnb['neighbourhood_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQp-ymqGOPa0"
   },
   "source": [
    "You can see the different types of neighborhoods are already well categorized. But what if it wasn’t?\n",
    "\n",
    "To simulate a scenario where some of the data had capitalization or spelling issues, I sampled 2 rows from the data, and replaced them with the wrong spelling.\n",
    "\n",
    "You can see now how the categorization is messed up. “Manhattan” and “manhatann” refer to the same thing, but they aren’t in the same category because of capitalization. Same goes for “brookln” due to spelling issues.\n",
    "\n",
    "We can fix this by using the replace function in pandas. We first give the values that are wrong, then supply the right ones. Notice the values have to match each other in the list, i.e. “manhatann” → “Manhattan”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ol-3qa6vOVI1"
   },
   "outputs": [],
   "source": [
    "random_index = airbnb.sample(2, random_state = 10).index\n",
    "\n",
    "# airbnb['neighbourhood_group'].loc[random_index]\n",
    "## we randomly selected Manhattan and Brooklyn\n",
    "\n",
    "wrong_spelling = ['manhatann', 'brookln']\n",
    "\n",
    "# replace them with the wrong spelling\n",
    "airbnb.loc[random_index,'neighbourhood_group'] = wrong_spelling\n",
    "airbnb['neighbourhood_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nP2CTf77OYOl"
   },
   "outputs": [],
   "source": [
    "airbnb['neighbourhood_group'].replace(['manhatann', 'brookln'],\n",
    "                             ['Manhattan', 'Brooklyn'], inplace=True)\n",
    "airbnb['neighbourhood_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9ImndLSOd_S"
   },
   "source": [
    "### Converting to DateTime\n",
    "\n",
    "If you have data that should be a datetime object, but are strings, you can use the pd.to_datetime, and pass it the format that represents your data.\n",
    "\n",
    "Just like that, the column has converted into a datatime data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YQ0YofCOkc8"
   },
   "outputs": [],
   "source": [
    "airbnb_ori['last_review'] = pd.to_datetime(airbnb_ori['last_review'], format='%Y-%m-%d')\n",
    "airbnb_ori['last_review'].dtype.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNX7eTVNOrNj"
   },
   "source": [
    "### Duplicates\n",
    "\n",
    "There are cases where your rows have duplicate values, this could’ve happened due to some mishaps in your data collection.\n",
    "\n",
    "To find out if you have duplicated values, call duplicated().any() on your data frame, and if it’s true, use the drop_duplicates function\n",
    "\n",
    "You can also specify columns where you want to remove duplicate values like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQJl99tTOlri"
   },
   "outputs": [],
   "source": [
    "airbnb.duplicated().any()\n",
    "\n",
    "## if true\n",
    "# airbnb.drop_duplicates()\n",
    "\n",
    "## if you want to drop duplicates at specific column\n",
    "# airbnb.drop('col_name', axis=1, inplace=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-orCcWMO2UT"
   },
   "source": [
    "### Change data type to reduce memory\n",
    "\n",
    "Changing data type is common if you want to reduce memory usage.\n",
    "\n",
    "To do so, you can use the astype(‘dtype’) function where you specify the dtype you want.\n",
    "\n",
    "In this case, I changed the data type for the host_id column from int64 to int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0pLpjbpPRWj"
   },
   "source": [
    "Observe the memory before changing the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRhYiLTXPKhH"
   },
   "outputs": [],
   "source": [
    "airbnb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dac63lSPOWm"
   },
   "source": [
    "And after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1P6AaRQHPN6W"
   },
   "outputs": [],
   "source": [
    "airbnb['host_id'] = airbnb['host_id'].astype('int32')\n",
    "airbnb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqmL2f1VPVNJ"
   },
   "source": [
    "You can see the memory reduced from 6.5+ to 6.3+ MB.\n",
    "\n",
    "[Here](https://stackoverflow.com/questions/15891038/change-column-type-in-pandas#:~:text=The%20best%20way%20to%20convert%20one%20or%20more%20columns%20of,floating%20point%20numbers%20as%20appropriate.) is more information on changing data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvOkx8JxPfIB"
   },
   "source": [
    "## 5. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AS6JOHbPhS3"
   },
   "source": [
    "Outliers can be dangerous as they can skew your model and give you predictions that are biased and erroneous.\n",
    "\n",
    "The best way to find outliers is to use the describe function and look at information such as maximum and mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iti2YqdiPkjr"
   },
   "outputs": [],
   "source": [
    "airbnb['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAlOel2YPmiY"
   },
   "source": [
    "You can also plot a histogram and look at the distribution of your data.\n",
    "\n",
    "In this histogram, you can see that most of the data is around 0 to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIoegNgyPqPe"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "airbnb['price'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIcn_Cq_Pz52"
   },
   "source": [
    "A boxplot is also useful in detecting outliers.\n",
    "\n",
    "As you can see, the price column has multiple data points that are outliers (above of the maximum in the boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eEHeP90P1D3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "airbnb.boxplot(column=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH-aJJqzP5nM"
   },
   "source": [
    "For categorical data, you can plot a bar chart to see whether a particular category to view the count of the categories.\n",
    "\n",
    "Outliers in categorical data is tricky, because you have to determine whether it’s appropriate to call it an outlier based on context.\n",
    "\n",
    "In some cases, outliers depend on context. In my example, you see that Manhattan and Brooklyn has significantly more data than Staten Island. This doesn’t count as an outlier, since Manhattan and Brooklyn has a higher housing density as compared to Staten Island."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6K9OicLGP-cm"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "airbnb['neighbourhood_group'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwFr5F71QL9S"
   },
   "source": [
    "### Dealing with outliers\n",
    "Dealing with outliers is similar to removing missing values, the only difference is the way you find outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j506D2BVNUt9"
   },
   "source": [
    "#### **Reference**\n",
    "Neo, Benedict. 2021. “Data Cleaning with Python.” Bitgrit Data Science Publication. May 21, 2021."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook1_data_clearning_toturial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
